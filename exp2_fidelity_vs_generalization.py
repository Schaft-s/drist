#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 2: –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å Fidelity vs Generalization

–¶–µ–ª—å: –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å fidelity vs generalization —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ 
–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã lambda –ø–µ—Ä–µ–¥ KL loss.

–ú–µ—Ç—Ä–∏–∫–∏:
- R(S_lambda) = CE(y, S_lambda)  - –æ–±–æ–±—â–∞–µ–º–æ—Å—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞
- F_cent(S_lambda) = E[KL(hat{T} | S_lambda)] - centroid fidelity
- F_avg(S_lambda) = E[KL(avg_T | S_lambda)] - average fidelity

–ü—Ä–æ—Ü–µ–¥—É—Ä–∞:
1. –ó–∞–≥—Ä—É–∂–∞–µ–º 5 –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö —É—á–∏—Ç–µ–ª–µ–π –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ 1
2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ lambda –≤ [0.0, 0.5, 1.0, 2.0, 5.0, 10.0]:
   - –û–±—É—á–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç—É–¥–µ–Ω—Ç (Centroid –º–µ—Ç–æ–¥)
   - –í—ã—á–∏—Å–ª—è–µ–º R(S_lambda), F_cent(S_lambda), F_avg(S_lambda)
3. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏:
   - |R(S_lambda) - R(hat{T})| vs sqrt(F_cent(S_lambda))
   - F_avg(S_lambda) vs F_cent(S_lambda)
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os
import argparse
import yaml
import sys
import json
import numpy as np
from collections import defaultdict

parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

from train_student.student_models import student_model_dict, count_parameters
from train_teachers.teacher_models import teacher_model_dict
from utils.distillation_losses import DistillKL
from utils.utils import compute_fidelity_metrics, evaluate_model


def load_config(config_path):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def get_dataloaders(dataset, batch_size):
    """–°–æ–∑–¥–∞–µ—Ç dataloaders"""
    if dataset == 'CIFAR10':
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465), 
                               (0.2023, 0.1994, 0.2010))
        ])
        train_dataset = datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
        test_dataset = datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
    else:
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
        
        if dataset == 'MNIST':
            train_dataset = datasets.MNIST(root='./data', train=True,
                                          download=True, transform=transform)
            test_dataset = datasets.MNIST(root='./data', train=False,
                                         download=True, transform=transform)
        else:  # FashionMNIST
            train_dataset = datasets.FashionMNIST(root='./data', train=True,
                                                 download=True, transform=transform)
            test_dataset = datasets.FashionMNIST(root='./data', train=False,
                                                download=True, transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size,
                             shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size,
                            shuffle=False, num_workers=2)
    
    return train_loader, test_loader


def load_teachers(teacher_names, teacher_dir, dataset, device):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö —É—á–∏—Ç–µ–ª–µ–π"""
    teachers = []
    num_classes = 10
    
    for name in teacher_names:
        model = teacher_model_dict[name](num_classes=num_classes)
        checkpoint_path = f'{teacher_dir}/{dataset.lower()}/{name}.pth'
        
        try:
            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)
            model.load_state_dict(checkpoint['model_state_dict'])
            model = model.to(device)
            model.eval()
            acc = checkpoint.get('test_acc', 0)
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω {name}: Test Acc = {acc:.2f}%")
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {name}: {e}")
            return None
        
        teachers.append((model, name))
    
    return teachers


def compute_centroid_fidelity(student, teachers, test_loader, device, temperature):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç Centroid Fidelity: KL(avg_logits_teachers | student_logits)
    """
    student.eval()
    
    total_kl = 0.0
    num_batches = 0
    
    with torch.no_grad():
        for data, labels in test_loader:
            data, labels = data.to(device), labels.to(device)
            
            # –õ–æ–≥–∏—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞
            logits_s = student(data)
            
            # –õ–æ–≥–∏—Ç—ã —É—á–∏—Ç–µ–ª–µ–π
            logits_t_list = []
            for teacher, _ in teachers:
                if hasattr(teacher, 'is_feat'):
                    _, logits_t = teacher(data, is_feat=True)
                else:
                    logits_t = teacher(data)
                logits_t_list.append(logits_t)
            
            # –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—á–∏—Ç–µ–ª–µ–π (—Ü–µ–Ω—Ç—Ä–æ–∏–¥)
            avg_logits_t = sum(logits_t_list) / len(logits_t_list)
            
            # KL divergence
            probs_t = F.softmax(avg_logits_t / temperature, dim=1)
            log_probs_s = F.log_softmax(logits_s / temperature, dim=1)
            kl = F.kl_div(log_probs_s, probs_t, reduction='batchmean')
            
            total_kl += kl.item()
            num_batches += 1
    
    return total_kl / num_batches


def compute_average_fidelity(student, teachers, test_loader, device, temperature):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç Average Fidelity: —Å—Ä–µ–¥–Ω–µ–µ KL —Å–æ –≤—Å–µ–º–∏ —É—á–∏—Ç–µ–ª—è–º–∏
    """
    student.eval()
    
    total_kl = 0.0
    num_batches = 0
    
    with torch.no_grad():
        for data, labels in test_loader:
            data, labels = data.to(device), labels.to(device)
            
            # –õ–æ–≥–∏—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞
            logits_s = student(data)
            
            batch_kl = 0.0
            for teacher, _ in teachers:
                if hasattr(teacher, 'is_feat'):
                    _, logits_t = teacher(data, is_feat=True)
                else:
                    logits_t = teacher(data)
                
                # KL divergence
                probs_t = F.softmax(logits_t / temperature, dim=1)
                log_probs_s = F.log_softmax(logits_s / temperature, dim=1)
                kl = F.kl_div(log_probs_s, probs_t, reduction='batchmean')
                batch_kl += kl.item()
            
            total_kl += batch_kl / len(teachers)
            num_batches += 1
    
    return total_kl / num_batches


def train_student_with_lambda(lambda_kd, student, teachers, train_loader, test_loader,
                              device, config, epochs=20):
    """
    –û–±—É—á–∞–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º lambda –ø–µ—Ä–µ–¥ KL loss
    
    Loss = CE(y, S) + lambda * KL(avg_T | S)
    """
    
    student = student.to(device)
    student.train()
    
    criterion_cls = nn.CrossEntropyLoss()
    criterion_kd = DistillKL(config['temperature'])
    optimizer = optim.Adam(student.parameters(), lr=config['lr'])
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    
    print(f"\n  –û–±—É—á–µ–Ω–∏–µ —Å lambda={lambda_kd}...")
    
    for epoch in range(epochs):
        student.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, labels) in enumerate(train_loader):
            data, labels = data.to(device), labels.to(device)
            
            # –õ–æ–≥–∏—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞
            logits_s = student(data)
            loss_cls = criterion_cls(logits_s, labels)
            
            # –°—Ä–µ–¥–Ω–∏–π –ª–æ–≥–∏—Ç —É—á–∏—Ç–µ–ª–µ–π
            with torch.no_grad():
                logits_t_list = []
                for teacher, _ in teachers:
                    if hasattr(teacher, 'is_feat'):
                        _, logits_t = teacher(data, is_feat=True)
                    else:
                        logits_t = teacher(data)
                    logits_t_list.append(logits_t)
                
                avg_logits_t = sum(logits_t_list) / len(logits_t_list)
            
            # KL loss
            loss_kd = criterion_kd(logits_s, avg_logits_t)
            
            # –û–±—â–∏–π loss
            loss = loss_cls + lambda_kd * loss_kd
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = logits_s.max(1)
            train_correct += predicted.eq(labels).sum().item()
            train_total += labels.size(0)
            
            if (batch_idx + 1) % 100 == 0:
                acc = 100. * train_correct / train_total
                print(f"    E{epoch+1} B{batch_idx+1}/{len(train_loader)} | "
                      f"Loss: {train_loss/(batch_idx+1):.4f}, Acc: {acc:.1f}%", end='\r')
        
        scheduler.step()
    
    print(f"\n  ‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å lambda={lambda_kd}")
    
    return student


def experiment_fidelity_vs_generalization(config):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2
    Fidelity vs Generalization —Å —Ä–∞–∑–Ω—ã–º–∏ lambda
    """
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\n–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    print(f"–î–∞—Ç–∞—Å–µ—Ç: {config['dataset']}")
    
    # Data loaders
    train_loader, test_loader = get_dataloaders(config['dataset'], config['batch_size'])
    print(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_loader.dataset)}")
    print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(test_loader.dataset)}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —É—á–∏—Ç–µ–ª–µ–π –∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ 1
    teacher_names_config = config['teacher_names']
    teachers = load_teachers(teacher_names_config, config['teacher_dir'], 
                            config['dataset'], device)
    
    if teachers is None:
        print("\n‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —É—á–∏—Ç–µ–ª–µ–π!")
        return
    
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ —É—á–∏—Ç–µ–ª–µ–π: {len(teachers)}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º baseline: —Ç–æ—á–Ω–æ—Å—Ç—å —É—á–∏—Ç–µ–ª–µ–π (—Ü–µ–Ω—Ç—Ä–æ–∏–¥)
    print("\n–í—ã—á–∏—Å–ª—è–µ–º baseline –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞ —É—á–∏—Ç–µ–ª–µ–π...")
    
    with torch.no_grad():
        teacher_accs = []
        for teacher, name in teachers:
            test_acc, _ = evaluate_model(teacher, test_loader, nn.CrossEntropyLoss(), device)
            teacher_accs.append(test_acc)
            print(f"  {name}: {test_acc:.2f}%")
        
        avg_teacher_acc = np.mean(teacher_accs)
        print(f"  –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å —É—á–∏—Ç–µ–ª–µ–π: {avg_teacher_acc:.2f}%")
    
    # Create save directory
    save_dir = f'{config["save_dir"]}/{config["dataset"].lower()}/exp2_fidelity_vs_gen2'
    os.makedirs(save_dir, exist_ok=True)
    
    # ========================================
    # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: —Ä–∞–∑–Ω—ã–µ lambda
    # ========================================
    
    lambdas = [0.0, 0.1, 0.01, 0.25, 0.025, 100.0, 1000]
    results = defaultdict(dict)
    
    print("\n" + "="*70)
    print("–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: Fidelity vs Generalization")
    print("="*70)
    
    for lambda_kd in lambdas:
        print(f"\n{'='*70}")
        print(f"Lambda = {lambda_kd}")
        print(f"{'='*70}")
        
        # –°–æ–∑–¥–∞—ë–º –∏ –æ–±—É—á–∞–µ–º —Å—Ç—É–¥–µ–Ω—Ç–∞
        student_model_name = config.get('student_model', 'student') # –ß–∏—Ç–∞–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        student = student_model_dict[student_model_name](num_classes=10).to(device)
        print(f"–°—Ç—É–¥–µ–Ω—Ç: {count_parameters(student):,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        # –û–±—É—á–∞–µ–º
        student = train_student_with_lambda(
            lambda_kd, student, teachers, train_loader, test_loader,
            device, config, epochs=config.get('exp2_epochs', 20)
        )
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        print(f"\n  –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏...")
        
        # 1. Generalization: R(S_lambda) = CE(y, S_lambda)
        test_acc, test_loss = evaluate_model(student, test_loader, nn.CrossEntropyLoss(), device)
        R_S = test_loss  # Cross-entropy loss
        generalization_gap = np.abs(test_acc - avg_teacher_acc)
        
        print(f"    Test Acc: {test_acc:.2f}%")
        print(f"    Test Loss (R): {R_S:.4f}")
        print(f"    Generalization gap: |{test_acc:.2f}% - {avg_teacher_acc:.2f}%| = {generalization_gap:.2f}%")
        
        # 2. Centroid Fidelity: F_cent(S_lambda)
        F_cent = compute_centroid_fidelity(student, teachers, test_loader, device, 
                                          config['temperature'])
        print(f"    Centroid Fidelity: {F_cent:.4f}")
        
        # 3. Average Fidelity: F_avg(S_lambda)
        F_avg = compute_average_fidelity(student, teachers, test_loader, device,
                                         config['temperature'])
        print(f"    Average Fidelity: {F_avg:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results[lambda_kd] = {
            'test_acc': test_acc,
            'test_loss': R_S,
            'generalization_gap': generalization_gap,
            'centroid_fidelity': F_cent,
            'average_fidelity': F_avg,
            'sqrt_F_cent': np.sqrt(F_cent)
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞
        save_path = f'{save_dir}/student_lambda_{lambda_kd}.pth'
        torch.save({
            'model_state_dict': student.state_dict(),
            'test_acc': test_acc,
            'lambda': lambda_kd
        }, save_path)
        print(f"    ‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
    
    # ========================================
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –∞–Ω–∞–ª–∏–∑
    # ========================================
    
    print("\n" + "="*70)
    print("–ò–¢–û–ì–ò –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê")
    print("="*70)
    
    print("\n–õ—è–º–±–¥–∞ | Test Acc | R(S_Œª) | Generalization Gap | F_cent | F_avg | sqrt(F_cent)")
    print("-" * 85)
    
    for lambda_kd in lambdas:
        res = results[lambda_kd]
        print(f"{lambda_kd:6.1f} | {res['test_acc']:7.2f}% | {res['test_loss']:6.4f} | "
              f"{res['generalization_gap']:8.2f}% | {res['centroid_fidelity']:6.4f} | "
              f"{res['average_fidelity']:6.4f} | {res['sqrt_F_cent']:6.4f}")
    
    # ========================================
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    # ========================================
    
    print(f"\n–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
    
    try:
        import matplotlib.pyplot as plt
        
        lambdas_list = sorted(lambdas)
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: |R(S_lambda) - R(hat{T})| vs sqrt(F_cent)
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        gen_gaps = [results[l]['generalization_gap'] for l in lambdas_list]
        sqrt_f_cents = [results[l]['sqrt_F_cent'] for l in lambdas_list]
        f_avgs = [results[l]['average_fidelity'] for l in lambdas_list]
        f_cents = [results[l]['centroid_fidelity'] for l in lambdas_list]
        
        # –ì—Ä–∞—Ñ–∏–∫ 1
        ax1 = axes[0]
        scatter1 = ax1.scatter(sqrt_f_cents, gen_gaps, s=200, c=lambdas_list, 
                              cmap='viridis', edgecolors='black', linewidth=2, alpha=0.7)
        
        for i, l in enumerate(lambdas_list):
            ax1.annotate(f'Œª={l}', (sqrt_f_cents[i], gen_gaps[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=10)
        
        ax1.set_xlabel('‚àöF_cent(S_Œª)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('|R(S_Œª) - R(TÃÇ)|, %', fontsize=12, fontweight='bold')
        ax1.set_title('Generalization Gap vs Centroid Fidelity', fontsize=13, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        plt.colorbar(scatter1, ax=ax1, label='Œª')
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: F_avg vs F_cent
        ax2 = axes[1]
        scatter2 = ax2.scatter(f_cents, f_avgs, s=200, c=lambdas_list,
                              cmap='viridis', edgecolors='black', linewidth=2, alpha=0.7)
        
        for i, l in enumerate(lambdas_list):
            ax2.annotate(f'Œª={l}', (f_cents[i], f_avgs[i]),
                        xytext=(5, 5), textcoords='offset points', fontsize=10)
        
        ax2.set_xlabel('F_cent(S_Œª)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('F_avg(S_Œª)', fontsize=12, fontweight='bold')
        ax2.set_title('Average Fidelity vs Centroid Fidelity', fontsize=13, fontweight='bold')
        ax2.grid(True, alpha=0.3)
        plt.colorbar(scatter2, ax=ax2, label='Œª')
        
        plt.tight_layout()
        plot_path = f'{save_dir}/fidelity_vs_generalization.png'
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        print(f"‚úì –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot_path}")
        plt.close()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # Test Accuracy vs Lambda
        test_accs = [results[l]['test_acc'] for l in lambdas_list]
        ax = axes[0, 0]
        ax.plot(lambdas_list, test_accs, 'o-', linewidth=2, markersize=8, label='Student', color='blue')
        ax.axhline(y=avg_teacher_acc, color='red', linestyle='--', linewidth=2, label='Avg Teacher')
        ax.set_xlabel('Œª', fontsize=11, fontweight='bold')
        ax.set_ylabel('Test Accuracy, %', fontsize=11, fontweight='bold')
        ax.set_title('Test Accuracy vs Œª', fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Centroid Fidelity vs Lambda
        ax = axes[0, 1]
        ax.plot(lambdas_list, f_cents, 's-', linewidth=2, markersize=8, color='green')
        ax.set_xlabel('Œª', fontsize=11, fontweight='bold')
        ax.set_ylabel('F_cent', fontsize=11, fontweight='bold')
        ax.set_title('Centroid Fidelity vs Œª', fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # Average Fidelity vs Lambda
        ax = axes[1, 0]
        ax.plot(lambdas_list, f_avgs, '^-', linewidth=2, markersize=8, color='orange')
        ax.set_xlabel('Œª', fontsize=11, fontweight='bold')
        ax.set_ylabel('F_avg', fontsize=11, fontweight='bold')
        ax.set_title('Average Fidelity vs Œª', fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # Generalization Gap vs Lambda
        ax = axes[1, 1]
        ax.plot(lambdas_list, gen_gaps, 'd-', linewidth=2, markersize=8, color='purple')
        ax.set_xlabel('Œª', fontsize=11, fontweight='bold')
        ax.set_ylabel('Generalization Gap, %', fontsize=11, fontweight='bold')
        ax.set_title('Generalization Gap vs Œª', fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot2_path = f'{save_dir}/metrics_vs_lambda.png'
        plt.savefig(plot2_path, dpi=150, bbox_inches='tight')
        print(f"‚úì –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot2_path}")
        plt.close()
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
    results_json = {str(k): v for k, v in results.items()}
    results_path = f'{save_dir}/experiment_results.json'
    with open(results_path, 'w') as f:
        json.dump(results_json, f, indent=2)
    print(f"‚úì –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")
    
    print(f"\n‚úì –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {save_dir}/")


if __name__ == '__main__':
    parser = argparse.ArgumentParser('–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2: Fidelity vs Generalization')
    parser.add_argument('--config', type=str, required=True,
                       help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É YAML')
    args = parser.parse_args()
    
    config = load_config(args.config)
    experiment_fidelity_vs_generalization(config)
